{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####1- previous pakage loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####2- Outline of the assignment\n",
    "#####Convolution functions, including:\n",
    "-Zero Padding\n",
    "-Convolve window\n",
    "-Convolution forward\n",
    "-Convolution backward (optional)\n",
    "\n",
    "Pooling functions, including:\n",
    "-Pooling forward\n",
    "-Create mask\n",
    "-Distribute value\n",
    "-Pooling backward (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####3- Zero padding exercise\n",
    "###### the shape of X is m * n_H * n_W * channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=\n",
    "                   0)\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x.shape =', (4, 3, 3, 2))\n('x_pad.shape =', (4, 7, 7, 2))\n('x[1, 1] =', array([[ 0.90085595, -0.68372786],\n       [-0.12289023, -0.93576943],\n       [-0.26788808,  0.53035547]]))\n('x_pad[1, 1] =', array([[ 0.,  0.],\n       [ 0.,  0.],\n       [ 0.,  0.],\n       [ 0.,  0.],\n       [ 0.,  0.],\n       [ 0.,  0.],\n       [ 0.,  0.]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11a1f6510>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e32c3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "print (\"x[1, 1] =\", x[1, 1])\n",
    "print (\"x_pad[1, 1] =\", x_pad[1, 1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####3.2- Single step of convolution\n",
    "* take an input volume\n",
    "* apply a filter in every position\n",
    "* output another vlolume(usually of different size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    s = np.multiply(a_slice_prev, W) +b\n",
    "    z = np.sum(s)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Z= ', -23.160212202520778)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "w= np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "z = conv_single_step(a_slice_prev, w, b)\n",
    "print(\"Z= \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####3.3- Convolutional Neural Network-Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    n_H = int((n_H_prev-f+2*pad)/stride+1)\n",
    "    n_W = int((n_W_prev-f+2*pad)/stride+1)\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    for i in range(m):\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f \n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[..., c], b[..., c])\n",
    "        \n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    return Z, cache\n",
    "                       \n",
    "       \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Z's mean =\", (10, 7, 7, 8))\n('cache_conv[0][1][2][3] =', array([-0.20075807,  0.18656139,  0.41005165]))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10, 4, 4, 3)\n",
    "W = np.random.randn(2, 2, 3, 8)\n",
    "b = np.random.rand(1, 1, 1, 8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 1}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\", Z.shape)\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Finally, CONV layer should also contain an activation, in which case we would add the following line of code:\n",
    "\n",
    "* Convolve the window to get back one output neuron\n",
    "- Z[i, h, w, c] = ...\n",
    "* Apply activation\n",
    "- [i, h, w, c] = activation(Z[i, h, w, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####4 POOLING Layer\n",
    "#####4-1 forward pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = 'max'):\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    n_H = int((n_H_prev - f)/stride + 1)\n",
    "    n_W = int((n_W_prev - f)/stride + 1)\n",
    "    n_C = n_C_prev \n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "    for i in range(m):\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + stride\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = vert_start + stride\n",
    "                    \n",
    "                    a_slice_prev = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    if mode == 'max':\n",
    "                        A[i, h, w, c] = np.max(a_slice_prev)\n",
    "                    if mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_slice_prev)\n",
    "    cache = (A_prev, hparameters)\n",
    "    assert (A.shape == (m, n_H, n_W, n_C))\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n('A =', array([[[[ 1.62434536, -0.61175641, -0.52817175]]],\n\n\n       [[[ 0.12015895,  0.61720311,  0.30017032]]]]), (2, 1, 1, 3))\n()\nmode = average\n('A =', array([[[[ 1.62434536, -0.61175641, -0.52817175]]],\n\n\n       [[[ 0.12015895,  0.61720311,  0.30017032]]]]), (2, 1, 1, 3))\n()\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hparameters = {\"stride\": 1, \"f\": 4}\n",
    "A, cache = pool_forward(A_prev, hparameters, mode='max')\n",
    "print(\"mode = max\")\n",
    "print(\"A =\", A,A.shape)\n",
    "print()\n",
    "A2, cache2 = pool_forward(A_prev, hparameters, mode=\"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A =\", A2, A2.shape)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####5- Backpropagation in CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    (m, n_W_prev, n_H_prev, n_C_prev) = A_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    dA_prev = np.zeros((n_W_prev, n_H_prev, n_C_prev))\n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "\n",
    "    for i in range(m):\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        da_prev_pad = dA_prev_pad[i]\n",
    "\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w\n",
    "                    horiz_end = horiz_start + f\n",
    "\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end]\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:, :, :, c] * dZ[i, h, w, c]\n",
    "                    dW[:, :, :, c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:, :, :, c] += dZ[i, h, w, c]\n",
    "                    dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "                    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
